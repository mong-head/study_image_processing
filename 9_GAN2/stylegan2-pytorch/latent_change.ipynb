{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install easydict tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melon\\anaconda3\\lib\\site-packages\\torch\\utils\\cpp_extension.py:274: UserWarning: Error checking compiler version for cl: [WinError 2] 지정된 파일을 찾을 수 없습니다\n",
      "  warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torchvision import utils\n",
    "from model import Generator\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "args = edict({'size':1024, #웬만하면 1024x1024로 고정\n",
    "              'channel_multiplier':2,\n",
    "              'truncation_mean': 4096,\n",
    "              'truncation': 0.7, #0.7~0.8주면 artifact줄어듦(정상적인 이미지가 나올 것임)\n",
    "              'sample': 1,\n",
    "              'ckpt':'./stylegan2-ffhq-config-f.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "args.latent = 512\n",
    "args.n_mlp = 8\n",
    "\n",
    "g_ema = Generator(\n",
    "    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",
    ").to(device)\n",
    "checkpoint = torch.load(args.ckpt, map_location='cpu')\n",
    "\n",
    "g_ema.load_state_dict(checkpoint[\"g_ema\"])\n",
    "\n",
    "if args.truncation < 1:\n",
    "    with torch.no_grad():\n",
    "        mean_latent = g_ema.mean_latent(args.truncation_mean)\n",
    "else:\n",
    "    mean_latent = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# application\n",
    "\n",
    "## 1. age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_vector = torch.from_numpy(np.load('./stylegan2directions/age.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# age들어가는 과정\n",
    "age = [-20,-10,0,10,20]\n",
    "with torch.no_grad():\n",
    "    g_ema.eval()\n",
    "    for i in tqdm(range(5)):\n",
    "        # generate random latent vector\n",
    "#         sample_z = torch.randn(args.sample, args.latent, device=device)\n",
    "        #torch.random.seed(1000)\n",
    "        #torch.random.seed()\n",
    "        torch.manual_seed(101)\n",
    "        random_latent = torch.randn(args.sample, args.latent, device=device) #나중에는 임의로 말고 특정 latent줄 수 있음\n",
    "        random_latent = g_ema.style(random_latent)\n",
    "        random_latent = random_latent.unsqueeze(1).repeat(1, 18, 1) #latent사이즈 늘려줌(?)\n",
    "        random_latent = random_latent + age[i] * age_vector.unsqueeze(0) #나이 들어가는 과정\n",
    "\n",
    "        sample, _ = g_ema(\n",
    "            [random_latent.to(dtype=torch.float)],\n",
    "            truncation=args.truncation,\n",
    "            truncation_latent=mean_latent,\n",
    "            input_is_latent=True\n",
    "        )\n",
    "\n",
    "        utils.save_image(\n",
    "            sample,\n",
    "            f\"sample/age/{str(i).zfill(6)}.png\",\n",
    "            nrow=1,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        ) # 실행시 sample폴더에 이미지 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_vector = torch.from_numpy(np.load('./stylegan2directions/gender.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# 성별 바뀌는 과정\n",
    "gender = [0,4,8,12,16]\n",
    "with torch.no_grad():\n",
    "    g_ema.eval()\n",
    "    for i in tqdm(range(5)):\n",
    "        # generate random latent vector\n",
    "#         sample_z = torch.randn(args.sample, args.latent, device=device)\n",
    "        #torch.random.seed(1000)\n",
    "        #torch.random.seed()\n",
    "        torch.manual_seed(101)\n",
    "        random_latent = torch.randn(args.sample, args.latent, device=device) #나중에는 임의로 말고 특정 latent줄 수 있음\n",
    "        random_latent = g_ema.style(random_latent)\n",
    "        random_latent = random_latent.unsqueeze(1).repeat(1, 18, 1) #latent사이즈 늘려줌(?)\n",
    "        random_latent = random_latent + gender[i] * gender_vector.unsqueeze(0) #나이 들어가는 과정\n",
    "\n",
    "        sample, _ = g_ema(\n",
    "            [random_latent.to(dtype=torch.float)],\n",
    "            truncation=args.truncation,\n",
    "            truncation_latent=mean_latent,\n",
    "            input_is_latent=True\n",
    "        )\n",
    "\n",
    "        utils.save_image(\n",
    "            sample,\n",
    "            f\"sample/gender/{str(i).zfill(6)}.png\",\n",
    "            nrow=1,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        ) # 실행시 sample폴더에 이미지 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toonify yourself\n",
    "\"\"\"\n",
    "https://colab.research.google.com/drive/1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk?usp=sharing#scrollTo=cwVXBFaSuoIU\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

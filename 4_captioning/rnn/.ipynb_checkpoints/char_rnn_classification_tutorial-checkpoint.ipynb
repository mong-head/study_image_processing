{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기\n",
    "********************************************************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
    "  **번역**: `황성수 <https://github.com/adonisues>`_\n",
    "\n",
    "\n",
    "단어를 분류하기 위해 기초적인 문자-단위 RNN을 구축하고 학습 할 예정입니다.\n",
    "이 튜토리얼에서는 (이후 2개 튜토리얼과 함께) NLP 모델링을 위한 데이터 전처리를\n",
    "`torchtext` 의 편리한 많은 기능들을 사용하지 않고 어떻게 하는지 \"기초부터(from scratch)\"\n",
    "보여주기 떄문에  NLP 모델링을 위한 전처리가 저수준에서 어떻게 진행되는지를 알 수 있습니다.\n",
    "문자-단위 RNN은 단어를 문자의 연속으로 읽어 들여서 각 단계의 예측과\n",
    "\"은닉 상태(Hidden State)\" 출력하고, 다음 단계에 이전 은닉 상태를 전달합니다.\n",
    "단어가 속한 클래스로 출력이 되도록 최종 예측으로 선택합니다.\n",
    "\n",
    "구체적으로, 18개 언어로 된 수천 개의 성(姓)을 훈련시키고,\n",
    "철자에 따라 이름이 어떤 언어인지 예측합니다:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hinton\n",
    "    (-0.47) Scottish\n",
    "    (-1.52) English\n",
    "    (-3.57) Irish\n",
    "\n",
    "    $ python predict.py Schmidhuber\n",
    "    (-0.19) German\n",
    "    (-2.48) Czech\n",
    "    (-2.68) Dutch\n",
    "\n",
    "\n",
    "**추천 자료:**\n",
    "\n",
    "Pytorch를 설치했고, Python을 알고, Tensor를 이해한다고 가정합니다:\n",
    "\n",
    "-  https://pytorch.org/ 설치 안내\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` PyTorch 시작하기\n",
    "-  :doc:`/beginner/pytorch_with_examples` 넓고 깊은 통찰을 위한 자료\n",
    "-  :doc:`/beginner/former_torchies_tutorial` 이전 Lua Torch 사용자를 위한 자료\n",
    "\n",
    "RNN과 작동 방식을 아는 것 또한 유용합니다:\n",
    "\n",
    "-  `The Unreasonable Effectiveness of Recurrent Neural\n",
    "   Networks <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n",
    "   실생활 예제를 보여 줍니다.\n",
    "-  `Understanding LSTM\n",
    "   Networks <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n",
    "   LSTM에 관한 것이지만 RNN에 관해서도 유익합니다.\n",
    "\n",
    "데이터 준비\n",
    "==================\n",
    "\n",
    ".. NOTE::\n",
    "   `여기 <https://download.pytorch.org/tutorial/data.zip>`__ 에서 데이터를 다운 받고,\n",
    "   현재 디렉토리에 압축을 푸십시오.\n",
    "\n",
    "``data/names`` 디렉토리에는 \"[Language].txt\" 라는 18 개의 텍스트 파일이 있습니다.\n",
    "각 파일에는 한 줄에 하나의 이름이 포함되어 있으며 대부분 로마자로 되어 있습니다\n",
    "(그러나, 유니코드에서 ASCII로 변환해야 함).\n",
    "\n",
    "각 언어 별로 이름 목록 사전 ``{language: [names ...]}`` 을 만듭니다.\n",
    "일반 변수 \"category\" 와 \"line\" (우리의 경우 언어와 이름)은 이후의 확장성을 위해 사용됩니다.\n",
    "\n",
    ".. NOTE::\n",
    "역자 주:  \"line\" 에 입력을 \"category\"에 클래스를 적용하여 다른 문제에도 활용 할 수 있습니다.\n",
    "여기서는 \"line\"에 이름(ex. Robert )를 입력으로 \"category\"에 클래스(ex. english)로 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentiment/pos_tweets.txt', 'sentiment/neg_tweets.txt']\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('sentiment/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# 유니코드 문자열을 ASCII로 변환, https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# 각 언어의 이름 목록인 category_lines 사전 생성\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# 파일을 읽고 줄 단위로 분리\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('sentiment/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 각 ``category`` (언어)를 ``line`` (이름)에 매핑하는 사전인\n",
    "``category_lines`` 를 만들었습니다. 나중에 참조 할 수 있도록\n",
    "``all_categories`` (언어 목록)와 ``n_categories`` 도 추적합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I cheer myself up when I'm down by listening to my playlist called, Genius Ballads and Cellos. I love my iPod and my taste of music.\", ' just watched the movie Wanted... it was pretty darn good.', \" now I'm happy \", \"plotting like i'm mike..'game planpass the ball to lebron AT ALL TIMES and DONT FOUL'..certainly we'll win  haha..go cavs goooo\", ' mcdonalds with my litto sis aka cuzin lol cristyyyyy ']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['pos_tweets'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이름을 Tensor로 변경\n",
    "--------------------------\n",
    "\n",
    "이제 모든 이름을 체계화 했으므로, 이를 활용하기 위해 Tensor로\n",
    "전환해야 합니다.\n",
    "\n",
    "하나의 문자를 표현하기 위해, 크기가 ``<1 x n_letters>`` 인\n",
    "\"One-Hot 벡터\" 를 사용합니다. One-Hot 벡터는 현재 문자의\n",
    "주소에만 1을 값으로 가지고 그외에 나머지는 0으로 채워진다.\n",
    "예시 ``\"b\" = <0 1 0 0 0 ...>`` .\n",
    "\n",
    "단어를 만들기 위해 One-Hot 벡터들을 2 차원 행렬\n",
    "``<line_length x 1 x n_letters>`` 에 결합시킵니다.\n",
    "\n",
    "위에서 보이는 추가적인 1차원은 PyTorch에서 모든 것이 배치(batch)에 있다고 가정하기\n",
    "때문에 발생합니다. 여기서는 배치 크기 1을 사용하고 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    ".. NOTE::\n",
    "역자 주:  One-Hot 벡터는 언어를 다룰 때 자주 이용되며,\n",
    "단어,글자 등을 벡터로 표현 할 때 단어,글자 사이의 상관 관계를 미리 알 수 없을 경우,\n",
    "One-Hot으로 표현하여 서로 직교한다고 가정하고 학습을 시작합니다.\n",
    "동일하게 상관 관계를 알 수 없는 다른 데이터의 경우에도 One-Hot 벡터를 활용 할 수 있습니다.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "# all_letters 로 문자의 주소 찾기, 예시 \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# 검증을 위해서 한개의 문자를 <1 x n_letters> Tensor로 변환\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# 한 줄(이름)을  <line_length x 1 x n_letters>,\n",
    "# 또는 One-Hot 문자 벡터의 Array로 변경\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크 생성\n",
    "====================\n",
    "\n",
    "Autograd 전에, Torch에서 RNN(recurrent neural network) 생성은\n",
    "여러 시간 단계 걸처서 계층의 매개변수를 복제하는 작업을 포함합니다.\n",
    "계층은 은닉 상태와 변화도(Gradient)를 가지며, 이제 이것들은 그래프 자체에서\n",
    "완전히 처리되는 됩니다. 이는 feed-forward 계층과\n",
    "같은 매우 \"순수한\" 방법으로 RNN을 구현할 수 있다는 것을 의미합니다.\n",
    "\n",
    "역자 주 : 여기서는 교육목적으로 nn.RNN 대신 직접 RNN을 사용합니다.\n",
    "\n",
    "이 RNN 모듈(대부분 `Torch 사용자를 위한 PyTorch 튜토리얼\n",
    "<https://pytorch.org/tutorials/beginner/former_torchies/\n",
    "nn_tutorial.html#example-2-recurrent-net>`__ 에서 복사함)\n",
    "은 입력 및 은닉 상태로 작동하는 2개의 선형 계층이며,\n",
    "출력 다음에 LogSoftmax 계층이 있습니다.\n",
    "\n",
    ".. figure:: https://i.imgur.com/Z2xbySO.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 네트워크의 한 단계를 실행하려면 입력(현재 문자 Tensor)과\n",
    "이전의 은닉 상태 (처음에는 0으로 초기화)를 전달해야 합니다.\n",
    "출력(각 언어의 확률)과 다음 은닉 상태 (다음 단계를 위해 유지)를\n",
    "돌려 받습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "input = letterToTensor('A')\n",
    "hidden =torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "효율성을 위해서 매 단계마다 새로운 Tensor를 만들고 싶지 않기 때문에\n",
    "``letterToTensor`` 대신 ``lineToTensor`` 를 잘라서 사용할\n",
    "것입니다. 이것은 Tensor의 사전 연산(pre-computing) 배치에 의해\n",
    "더욱 최적화 될 수 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7012, -0.6852]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보시다시피 출력은 ``<1 x n_categories>`` Tensor이고, 모든 항목은\n",
    "해당 카테고리의 우도(likelihood) 입니다 (더 높은 것이 더 확률 높음).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습\n",
    "========\n",
    "학습 준비\n",
    "----------------------\n",
    "\n",
    "학습으로 들어가기 전에 몇몇 도움되는 함수를 만들어야합니다.\n",
    "첫째는 우리가 알아낸 각 카테고리의 우도인 네트워크 출력을 해석하는 것 입니다.\n",
    "가장 큰 값의 주소를 알기 위해서 ``Tensor.topk`` 를 사용 할 수 있습니다.\n",
    "역자 주: 네트워크 출력(각 카테고리의 우도)으로\n",
    "가장 확률이 높은 카테고리 이름(언어)과 카테고리 번호 반환\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg_tweets', 1)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1) # 텐서의 가장 큰 값 및 주소\n",
    "    category_i = top_i[0].item()     # 텐서에서 정수 값으로 변경\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 예시(하나의 이름과 그 언어)를 얻는 빠른 방법도 필요합니다.:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = pos_tweets / line = Let's Go Lakers  Kick em in the Nuggs haha.\n",
      "category = neg_tweets / line = Still doing my homework \n",
      "category = pos_tweets / line = BradmanTV Thanks....it seemed the right moment. I love your show.  Your songs bring me joy.\n",
      "category = neg_tweets / line = melissaohh yeh. he had cancer didnt he \n",
      "category = neg_tweets / line = and the labtop just got messed up now i cant look at the lessons and tips i hope the psp can go to the website \n",
      "category = neg_tweets / line = I finally found iPod headphones that are meant for apple. they're madddd loud.  days \n",
      "category = neg_tweets / line = hillaryrachel oh i know how you feel. i took a leap of faith and asked Taylor Swift to be my BFFL ... she didnt reply \n",
      "category = pos_tweets / line = DJTinaSapp Ha I'll get it back to you as soon as possible \n",
      "category = neg_tweets / line = jessgirl I still feel like crap. The fever is alive and well. \n",
      "category = neg_tweets / line = Vicstar   Game's over.. Screw the Lakers\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크 학습\n",
    "--------------------\n",
    "\n",
    "이제 이 네트워크를 학습하는데 필요한 예시(학습 데이터)들을 보여주고 추정합니다.\n",
    "만일 틀렸다면 알려 줍니다.\n",
    "\n",
    "RNN의 마지막 계층이 ``nn.LogSoftmax`` 이므로 손실 함수로\n",
    "``nn.NLLLoss`` 가 적합합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 학습 루프는 다음과 같습니다:\n",
    "\n",
    "-  입력과 목표 Tensor 생성\n",
    "-  0 로 초기화된 은닉 상태 생성\n",
    "-  각 문자를 읽기\n",
    "\n",
    "   -  다음 문자를 위한 은닉 상태 유지\n",
    "\n",
    "-  목표와 최종 출력 비교\n",
    "-  역전파\n",
    "-  출력과 손실 반환\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # 이것을 너무 높게 설정하면 발산할 수 있고, 너무 낮으면 학습이 되지 않을 수 있습니다.\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # 매개변수의 경사도에 학습률을 곱해서 그 매개변수의 값에 더합니다.\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 예시 데이터를 사용하여 실행해야합니다. ``train`` 함수가 출력과 손실을\n",
    "반환하기 때문에 추측을 화면에 출력하고 도식화를 위한 손실을 추적 할 수\n",
    "있습니다. 1000개의 예시 데이터가 있기 때문에 ``print_every`` 예제만\n",
    "출력하고, 손실의 평균을 얻습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (2m 4s) 0.6136 Morning Tweetland, a long day ahead Hope everyone has a great day   / pos_tweets ✓\n",
      "10000 10% (3m 38s) 0.4695 laying in bed with no voice..  / neg_tweets ✓\n",
      "15000 15% (5m 41s) 0.4017 No Lebron Kobe finals like we hoped for grrrr  / neg_tweets ✓\n",
      "20000 20% (7m 6s) 0.5477 Doing Beat the Bridge race in Seattle this morning Should b beautiful  / pos_tweets ✓\n",
      "25000 25% (8m 44s) nan is at work and saddened due to Ted Baker London not being able to ship to the continental US  I want the hat / pos_tweets ✗ (neg_tweets)\n",
      "30000 30% (10m 22s) nan PrincessSuperC Cavs down by   mins left... just in case u arent watching.. its over for Lebron  / pos_tweets ✗ (neg_tweets)\n",
      "35000 35% (11m 41s) nan Missing My BFF  watching home and away it reminds me of her and me  we  / pos_tweets ✗ (neg_tweets)\n",
      "40000 40% (12m 56s) nan Jonasbrothers Nice skillz Nick  x love always, Marjorie  / pos_tweets ✓\n",
      "45000 45% (14m 13s) nan Now on park and ride bus back to my car but haven't got my Ipod today  / pos_tweets ✗ (neg_tweets)\n",
      "50000 50% (15m 35s) nan Today is National Cancer Survivors Day Congratulations today is a celebration woohoo  / pos_tweets ✓\n",
      "55000 55% (16m 48s) nan also, SOOOOO excited to see Taylor Swift, in Omaha, August th  / pos_tweets ✓\n",
      "60000 60% (18m 5s) nan Long night I feel terrible because I didn't eat before I went to work Headache, muscle aches, and an all over  / pos_tweets ✗ (neg_tweets)\n",
      "65000 65% (19m 42s) nan Is going to Vegas but wanting to go to Seattle  / pos_tweets ✗ (neg_tweets)\n",
      "70000 70% (21m 18s) nan FoxxFiles nah...The Cavs are done  Go Magic / pos_tweets ✓\n",
      "75000 75% (22m 40s) nan gilbirmingham Gil I'm sorry you won't get to Sydney as well next week for Supernova  you're only going to Perth, is that correct / pos_tweets ✗ (neg_tweets)\n",
      "80000 80% (24m 7s) nan Seattle is sunny atm.   Need to go take advantage of it before it rains again.   I'm outta here for a bit..    / pos_tweets ✓\n",
      "85000 85% (25m 27s) nan IN DESPERATE NEED FOR IPHONE MONEY srsly, me needs a phone that works   AND ITUNES MONEY O / pos_tweets ✗ (neg_tweets)\n",
      "90000 90% (26m 43s) nan It's no longer sunny in Seattle.  httptr.imsunnyinseattle / pos_tweets ✗ (neg_tweets)\n",
      "95000 95% (28m 35s) nan VerseTheVillain No problem Sad thing is I can't listen to it 'cause my phone won't load the player  is it in YouTube form or will it be / pos_tweets ✗ (neg_tweets)\n",
      "100000 100% (30m 8s) nan just got home from watching Michigan State get tromped    / pos_tweets ✗ (neg_tweets)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# 도식화를 위한 손실 추적\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # iter 숫자, 손실, 이름, 추측 화면 출력\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # 현재 평균 손실을 전체 손실 리스트에 추가\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 도식화\n",
    "--------------------\n",
    "\n",
    "``all_losses`` 를 이용한 손실 도식화는\n",
    "네트워크의 학습을 보여준다:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1078fe898>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 평가\n",
    "======================\n",
    "\n",
    "네트워크가 다른 카테고리에서 얼마나 잘 작동하는지 보기위해\n",
    "모든 실제 언어(행)가 네트워크에서 어떤 언어로 추측(열)되는지를 나타내는\n",
    "혼란 행열(confusion matrix)을 만듭니다. 혼란 행렬을 계산하기 위해\n",
    "``evaluate()`` 로 많은 수의 샘플을 네트워크에 실행합니다.\n",
    "``evaluate()`` 은 ``train ()`` 과 역전파를 빼면 동일합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-dd97d7c57743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 도식 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 혼란 행렬에서 정확한 추측을 추적\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "# 주어진 라인의 출력 반환\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# 예시들 중에 어떤 것이 정확하게 예측되었는지 기록\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# 모든 행을 합계로 나누어 정규화\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# 도식 설정\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# 축 설정\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# 모든 tick에서 레이블 지정\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주축에서 벗어난 밝은 점을 선택하여 잘못 추측한 언어를 표시\n",
    "할 수 있습니다. 예를 들어 한국어는 중국어로 이탈리아어로 스페인어로.\n",
    "그리스어는 매우 잘되는 것으로 영어는 매우 나쁜것으로 보입니다.\n",
    "(다른 언어들과 중첩 때문으로 추정)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 입력으로 실행\n",
    "---------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Dovesky\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cd7dc16e783d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_categories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dovesky'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jackson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Satoshi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-cd7dc16e783d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(input_line, n_predictions)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Get top N categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Dovesky', n_predictions=2)\n",
    "predict('Jackson', n_predictions=2)\n",
    "predict('Satoshi', n_predictions=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`실용 PyTorch 저장소\n",
    "<https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n",
    "의 최종 버전 스크립트는 위 코드를 몇개의 파일로 분할했습니다.:\n",
    "\n",
    "-  ``data.py`` (파일 읽기)\n",
    "-  ``model.py`` (RNN 정의)\n",
    "-  ``train.py`` (학습 실행)\n",
    "-  ``predict.py`` (커멘드 라인 인자로 ``predict()`` 실행)\n",
    "-  ``server.py`` (bottle.py를 사용하여 JSON API로 예측 제공)\n",
    "\n",
    "학습과 네트워크 저장을 위해 ``train.py`` 실행.\n",
    "\n",
    "이름으로 예측을 보기 위해 ``predict.py`` 실행:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hazaki\n",
    "    (-0.42) Japanese\n",
    "    (-1.39) Polish\n",
    "    (-3.51) Czech\n",
    "\n",
    "``server.py`` 를 실행하고 예측의 JSON 출력을 얻기 위해\n",
    "http://localhost:5533/Yourname 방문.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습\n",
    "=========\n",
    "\n",
    "-  \"line -> category\" 의 다른 데이터 집합으로 시도해보십시오, 예를 들어:\n",
    "\n",
    "   -  단어 -> 언어\n",
    "   -  이름 -> 성별\n",
    "   -  캐릭터 이름 -> 작가\n",
    "   -  페이지 제목 -> 블로그 또는 서브레딧\n",
    "\n",
    "-  더 크고 더 나은 모양의 네트워크로 더 나은 결과를 얻으십시오.\n",
    "\n",
    "   -  더많은 선형 계층을 추가해 보십시오\n",
    "   -  ``nn.LSTM`` 과 ``nn.GRU`` 계층을 추가해 보십시오\n",
    "   -  여러 개의 이런 RNN을 상위 수준 네트워크로 결합해 보십시오\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
